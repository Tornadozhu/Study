# XTuner 微调实践微调

## 配置环境

### 配置环境（使用 conda 构建一个 Python-3.10 的虚拟环境）

![image](https://github.com/user-attachments/assets/38764113-94e9-4c27-94a1-ac4c9db96dc1)

### 安装 XTuner

![image](https://github.com/user-attachments/assets/64266ed9-5306-4ad9-b112-2f11a8b49b3d)

### 验证安装

![image](https://github.com/user-attachments/assets/baaa7505-4065-4f0e-b8e5-612f17a3d1d0)


## 修改数据

### 创建一个新的文件夹用于存储微调数据

![image](https://github.com/user-attachments/assets/f378c284-87be-4bbc-893b-54cf10353dd5)


### 创建修改脚本

![image](https://github.com/user-attachments/assets/164474da-1ebb-488e-9c85-6ad20987a570)


### 执行脚本

![image](https://github.com/user-attachments/assets/4a8e6988-e17f-4a17-b3c7-fcf6ec9cc591)



### 查看数据

![image](https://github.com/user-attachments/assets/dbafa729-1637-4d3d-8c88-d075fe0f6c21)




## 训练启动

### 复制模型

在InternStudio开发机中的已经提供了微调模型，直接软链接即可

![image](https://github.com/user-attachments/assets/4ed575db-fa4b-4f5b-b5c6-88c0a3593e13)


### 修改 Config

获取官方写好的 config

![image](https://github.com/user-attachments/assets/6d732851-80a4-47d4-bb27-7fdab39b0183)

 ![image](https://github.com/user-attachments/assets/21d5c852-e57a-4c80-adcd-3ddea6403099)

 ![image](https://github.com/user-attachments/assets/2c25523d-109a-4e4f-b917-3d9e959d4c75)

 ![image](https://github.com/user-attachments/assets/5f1dead4-58ec-4729-933a-9bcf594e96b5)

### 启动微调

![image](https://github.com/user-attachments/assets/62d45c9e-5d32-492f-9cb1-cfc122b01937)

![image](https://github.com/user-attachments/assets/aff62366-0609-44e3-b756-dd3d091b0601)

成功完成微调

![image](https://github.com/user-attachments/assets/0ed628cd-7c4d-4d96-aef8-84738fbe62fe)



### 权重转换

模型转换的本质其实就是将原本使用 Pytorch 训练出来的模型权重文件转换为目前通用的 HuggingFace 格式文件，那么我们可以通过以下命令来实现一键转换。

![image](https://github.com/user-attachments/assets/a56a16f0-a8f8-4f5b-9b4c-26405f925f75)

目录结构变化（可以简单理解：LoRA 模型文件 = Adapter）

![image](https://github.com/user-attachments/assets/947fd95b-5319-4c72-930e-132f3dc5a0d5)



### 模型合并

对于 LoRA 或者 QLoRA 微调出来的模型其实并不是一个完整的模型，而是一个额外的层（Adapter），训练完的这个层最终还是要与原模型进行合并才能被正常的使用。

对于全量微调的模型（full）其实是不需要进行整合这一步的，因为全量微调修改的是原模型的权重而非微调一个新的 Adapter ，因此是不需要进行模型整合的。

![image](https://github.com/user-attachments/assets/1c18b3e6-2130-4037-af6f-ef4597cdedca)

![image](https://github.com/user-attachments/assets/f330ae95-c8bd-4378-8bba-c42d0c5bc913)



## 模型 WebUI 对话

修改模型路径

![image](https://github.com/user-attachments/assets/3bbfd648-0785-4eca-958b-078bddd55ba1)

启动应用

![image](https://github.com/user-attachments/assets/ff6940b0-f375-4a3c-bf1e-321da5f1061a)

![image](https://github.com/user-attachments/assets/83d1f049-4784-4c66-af90-dbea589f69f4)







