# L1G1000 书生大模型全链路开源体系


## 书生·蒲语官网地址：https://internlm.intern-ai.org.cn/

## 书生·蒲语Github地址：https://github.com/internLM/


## 书生·蒲语开源之路
![image](https://github.com/user-attachments/assets/ad4140a8-7645-493c-95dc-4eb0b7177807)


## 书生·蒲语概况

1、推理能力强领先：相对InternLM2 提升20%

2、支持100万字上下文

3、针对复杂问题效率提升60倍

![image](https://github.com/user-attachments/assets/305c621b-b22e-4993-be09-71083710e0ab)




## 模型能力飞轮

数据驱动的模型

![image](https://github.com/user-attachments/assets/956f591e-5f0a-46f4-bfb4-96fa1d390231)

## 高质量合成数据

1、基于规则的数据构造

2、基于模型的数据扩充

3、基于反馈的数据生成

![image](https://github.com/user-attachments/assets/4d0e76e1-8658-4753-b2fd-d61be5f2d37a)

## 领先的推理性能


![image](https://github.com/user-attachments/assets/9e45da05-c958-4df2-9847-444ee84ea506)

100万Token上下文 ——大海捞针实验 （几乎全绿）

![image](https://github.com/user-attachments/assets/e5177810-89cf-4368-9f86-6390ef5b3d2b)






